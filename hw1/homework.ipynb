{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1426a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ab1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "465aff70",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module.\n",
    "\n",
    "\n",
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"**Green** Taxi Trip Records\", we'll use \"**Yellow** Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2022.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "* 16\n",
    "* 17\n",
    "* 18\n",
    "* 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515ecb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./data/yellow_tripdata_2022-01.parquet')\n",
    "len(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a07bf238",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "* 41.45\n",
    "* 46.45\n",
    "* 51.45\n",
    "* 56.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "612fd739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.44529571272228"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "np.std(df.duration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47b64b7a",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "* 90%\n",
    "* 92%\n",
    "* 95%\n",
    "* 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d792c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827547930522406"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_before = len(df)\n",
    "df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "len_after = len(df)\n",
    "len_after/len_before"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8098ea4",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "* 2\n",
    "* 155\n",
    "* 345\n",
    "* 515\n",
    "* 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "632af525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "train_dicts = df[categorical].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_train.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e145624",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 6.99\n",
    "* 11.99\n",
    "* 16.99\n",
    "* 21.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5993d3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.98619083458946"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'duration'\n",
    "y_train = df[target].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "mean_squared_error(y_train, y_pred, squared=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "256f5200",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2022). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 7.79\n",
    "* 12.79\n",
    "* 17.79\n",
    "* 22.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6631e5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.78640785205543"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_parquet('./data/yellow_tripdata_2022-02.parquet')\n",
    "\n",
    "df2['duration'] = df2.tpep_dropoff_datetime - df2.tpep_pickup_datetime\n",
    "df2.duration = df2.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "df2 = df2[(df2.duration >= 1) & (df2.duration <= 60)]\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "df2[categorical] = df2[categorical].astype(str)\n",
    "\n",
    "val_dicts = df2[categorical].to_dict(orient='records')\n",
    "\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "target = 'duration'\n",
    "y_val = df2[target].values\n",
    "\n",
    "y_pred2 = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred2, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648119f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
